{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pickle as pickle\n",
    "import scipy.stats\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unwanted_chars = ['\\\\','.',',','/','\\'s']\n",
    "start = ['<null>']\n",
    "\n",
    "label_dict = {'neutral':0,'contradiction':1,'entailment':2}\n",
    "\n",
    "def load_data(path): #load SNLI words\n",
    "    '''\n",
    "    Constructs 4 dictionaries with the same key values across the dictionaries\n",
    "    '''\n",
    "    #data = []\n",
    "    excluded = 0\n",
    "    hypothesis = {}\n",
    "    premise = {}\n",
    "    label = {}\n",
    "    label_enc = {}\n",
    "    with open(path, 'r') as f:\n",
    "        #need this so indexing is continuous when sentences are skipped over\n",
    "        idx = 0\n",
    "        for i,line in enumerate(f):\n",
    "            obj = json.loads(line)\n",
    "            #skip these rows per readme\n",
    "            if obj[\"gold_label\"] == '-':\n",
    "                excluded += 1\n",
    "            else:\n",
    "                label[idx] = obj[\"gold_label\"]\n",
    "                label_enc[idx] = label_dict[obj[\"gold_label\"]]\n",
    "                premise[idx] = obj[\"sentence1\"]\n",
    "                hypothesis[idx] = obj[\"sentence2\"]\n",
    "                idx += 1\n",
    "    print('%s excluded' %excluded)\n",
    "    return hypothesis, premise, label, label_enc\n",
    "\n",
    "def load_embeddings(path,words_to_load,emb_dim): #load pre-trained GloVe embeddings\n",
    "    with open(path) as f:\n",
    "        loaded_embeddings = np.zeros((words_to_load, emb_dim))\n",
    "        words = {}\n",
    "        idx2words = {}\n",
    "        ordered_words = []\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= words_to_load: \n",
    "                break\n",
    "            s = line.split()\n",
    "            loaded_embeddings[i, :] = np.asarray(s[1:])\n",
    "            words[s[0]] = i\n",
    "            idx2words[i] = s[0]\n",
    "            ordered_words.append(s[0])\n",
    "\n",
    "    return loaded_embeddings, words, idx2words, ordered_words\n",
    "            \n",
    "def add_tokens(idx_mapping, embeddings, emb_dim):\n",
    "    '''\n",
    "    This function increases the index of the word to index mapping for GloVe so that\n",
    "    0: padding index\n",
    "    1: unk\n",
    "    2: BoS\n",
    "    '''\n",
    "    words_cnt = Counter(idx_mapping)\n",
    "    increment = Counter(dict.fromkeys(words, 3))\n",
    "    words_cnt = words_cnt + increment\n",
    "    words_cnt['<PAD_IDX>'] = 0\n",
    "    words_cnt['<UNK>'] = 1\n",
    "    words_cnt['<BoS>'] = 2\n",
    "    \n",
    "    #insert embeddings for tokens\n",
    "    '''\n",
    "    TO DO: FIX INITILIZATION\n",
    "    '''\n",
    "    #<BoS>\n",
    "    print(embeddings.shape)\n",
    "    embed = np.insert(embeddings,[0],np.random.rand(300),axis=0)\n",
    "    print(embed.shape)\n",
    "    #<UNK>\n",
    "    embed = np.insert(embed,[0],np.random.rand(300),axis=0)\n",
    "    print(embed.shape)\n",
    "    #<PAD_IDX>\n",
    "    embed = np.insert(embed,[0],np.zeros(300),axis=0)\n",
    "    print(embed.shape)\n",
    "    \n",
    "    return words_cnt, embed\n",
    "\n",
    "def clean_words(text_list): # Removes characters and makes all words lowercase\n",
    "    for i,word in enumerate(text_list):\n",
    "        for ch in unwanted_chars:\n",
    "            if ch in text_list[i]:\n",
    "                text_list[i] = text_list[i].replace(ch,'')\n",
    "            text_list[i] = text_list[i].lower()\n",
    "\n",
    "def tokenize(text_dict, idx_mapping, pad_len):\n",
    "    '''\n",
    "    text_dict: dictionary with index as key, sentence as value\n",
    "    returns dictionary with the index as key, sentenece mapped to index as value, and padded to pad_len\n",
    "    \n",
    "    QUESTION: How should we choose pad_len?  Should we truncate or should we set to the max length of \n",
    "    premise and hypothesis?\n",
    "    '''\n",
    "    tokenized_data = {}\n",
    "    for i in range(len(text_dict.keys())):\n",
    "        text_list = text_dict[i].split()\n",
    "        clean_words(text_list)\n",
    "        text_idx = []\n",
    "        for word in text_list:\n",
    "            try:\n",
    "                text_idx.append(idx_mapping[word])\n",
    "            except KeyError:\n",
    "                #UNK token\n",
    "                text_idx.append(1)\n",
    "                continue\n",
    "        #insert BoS token\n",
    "        text_idx.insert(0,2)\n",
    "        if len(text_idx) > pad_len:\n",
    "            text_idx = text_idx[:pad_len]\n",
    "        text_idx = np.concatenate((text_idx,np.zeros(max(pad_len-len(text_idx),0))))\n",
    "                                    \n",
    "        tokenized_data[i] = np.array(text_idx).astype(int)\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for lisa's laptop\n",
    "vocab_size = 50000\n",
    "emb_dim = 300\n",
    "num_classes = 3\n",
    "learning_rate = .05\n",
    "path = '/Users/Lisa/Documents/Grad School/DS-GA 1101/data/'\n",
    "glove_path = path+'glove.6B/glove.6B.300d.txt'\n",
    "text_path = path+'snli_1.0/snli_1.0_train.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 50000\n",
    "emb_dim = 300\n",
    "num_classes = 3\n",
    "#do we use learning rate anywhere?\n",
    "learning_rate = .05\n",
    "glove_path = 'glove/glove.6B.300d.txt'\n",
    "text_path = 'snli_1.0/snli_1.0_train.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785 excluded\n"
     ]
    }
   ],
   "source": [
    "hypothesis, premise, label, label_enc = load_data(text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, words, idx2words, ordered_words = load_embeddings(glove_path, vocab_size, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 300)\n",
      "(50001, 300)\n",
      "(50002, 300)\n",
      "(50003, 300)\n"
     ]
    }
   ],
   "source": [
    "#modifies embeddings, words, idx2words in place to add tokens\n",
    "words, embeddings = add_tokens(words, embeddings, emb_dim)\n",
    "idx2words = {v:k for k,v in words.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_len = 10\n",
    "p_len = 15\n",
    "h_idx = tokenize(hypothesis, words, h_len)\n",
    "p_idx = tokenize(premise, words, p_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = path+'pickles/'\n",
    "with open(fp+'h_idx.pt', 'wb') as f:\n",
    "    pickle.dump(h_idx, f)\n",
    "with open(fp+'p_idx.pt', 'wb') as f:\n",
    "    pickle.dump(p_idx, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample indices\n",
    "idx_list = np.array((0,1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_test_batch = torch.LongTensor(4, h_len)\n",
    "p_test_batch = torch.LongTensor(4, p_len)\n",
    "l_test_batch = torch.LongTensor(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test batch\n",
    "for i in idx_list:\n",
    "    h_test_batch[i] = torch.from_numpy(h_idx[i])\n",
    "    p_test_batch[i] = torch.from_numpy(p_idx[i])\n",
    "    l_test_batch[i] = label_enc[i]\n",
    "h_test_batch = h_test_batch.long()\n",
    "p_test_batch = p_test_batch.long()\n",
    "l_test_batch = Variable(l_test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecomposableAttention(nn.Module):\n",
    "    '''\n",
    "    Starting with premise (a), we see if the hypothesis (b) is an \n",
    "    entailment, a contradiction, or neutral.\n",
    "    '''\n",
    "    def __init__(self, glove_emb, batch_size, hidden_size, h_len, p_len, num_classes, dropout=0.2):\n",
    "        super(DecomposableAttention, self).__init__()\n",
    "        self.glove = glove_emb\n",
    "        self.num_embeddings = glove_emb.shape[0]\n",
    "        self.embedding_dim = glove_emb.shape[1]\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.compare_dim = 2*self.embedding_dim\n",
    "        self.aggregate_dim = 2*self.compare_dim\n",
    "        self.h_len = h_len\n",
    "        self.p_len = p_len\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embed = nn.Embedding(self.num_embeddings, self.embedding_dim)\n",
    "        \n",
    "        '''\n",
    "        Should the linear layers have a bias?  How many layers should we have in our feed forward network?\n",
    "        Yes?\n",
    "        '''\n",
    "        \n",
    "        self.F_a = nn.Linear(self.embedding_dim*self.p_len,self.embedding_dim*self.p_len)\n",
    "        self.F_b = nn.Linear(self.embedding_dim*self.h_len,self.embedding_dim*self.h_len)\n",
    "        \n",
    "        self.G_a = nn.Linear(self.embedding_dim*2,self.compare_dim)\n",
    "        self.G_b = nn.Linear(self.embedding_dim*2,self.compare_dim)\n",
    "        \n",
    "        self.H = nn.Linear(self.compare_dim,self.aggregate_dim)\n",
    "        self.output = nn.Linear(self.aggregate_dim,3)\n",
    "        \n",
    "        '''\n",
    "        MLP LAYERS\n",
    "        '''\n",
    "        self.mlp_f = self._mlp_layers(self.hidden_size, self.hidden_size)\n",
    "        self.mlp_g = self._mlp_layers(2 * self.hidden_size, self.hidden_size)\n",
    "        self.mlp_h = self._mlp_layers(2 * self.hidden_size, self.hidden_size)\n",
    "        \n",
    "        '''\n",
    "        Linear Layers\n",
    "        '''\n",
    "        self.project_embed = nn.Linear(self.embedding_dim,self.hidden_size)\n",
    "        self.final_linear = nn.Linear(self.hidden_size,self.num_classes)\n",
    "       \n",
    "        self.init_weights()\n",
    "    \n",
    "    def _mlp_layers(self, input_dim, output_dim):\n",
    "        mlp_layers = []\n",
    "        mlp_layers.append(nn.Dropout(p=self.dropout))\n",
    "        mlp_layers.append(nn.Linear(\n",
    "            input_dim, output_dim, bias=True))\n",
    "        mlp_layers.append(nn.ReLU())\n",
    "        mlp_layers.append(nn.Dropout(p=self.dropout))\n",
    "        mlp_layers.append(nn.Linear(\n",
    "            output_dim, output_dim, bias=True))\n",
    "        mlp_layers.append(nn.ReLU())   \n",
    "        #sequential runs all the layers in order\n",
    "        return nn.Sequential(*mlp_layers)  \n",
    "    \n",
    "    def forward(self, hypothesis, premise, label):\n",
    "        start_time = time.time()\n",
    "        '''\n",
    "        Embedding layer (only projection layer is trained)\n",
    "        max length = max length of of hypothesis/premise (respectively) in batch\n",
    "        Input dim: batch size x max length\n",
    "        Output dim: batch size x max length x hidden dimensions\n",
    "        '''\n",
    "        p_embedded = self.embed(Variable(premise))\n",
    "        h_embedded = self.embed(Variable(hypothesis))\n",
    "        #project from embedding dim to hidden dim\n",
    "        p_projected = self.project_embed(p_embedded.view(-1,self.embedding_dim))\\\n",
    "                                         .view(self.batch_size,-1,self.hidden_size)\n",
    "        h_projected = self.project_embed(h_embedded.view(-1,self.embedding_dim))\\\n",
    "                                         .view(self.batch_size,-1,self.hidden_size)\n",
    "        \n",
    "        '''\n",
    "        Relu layer (F from paper)\n",
    "        max length = max length of of hypothesis/premise (respectively) in batch\n",
    "        Input dim: batch size x max length x embedding dimensions\n",
    "        Output dim: batch size x max length x hidden dimension\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        OLD SINGLE LAYER\n",
    "        F_a = self.F_a(p_embedded.view(self.batch_size,-1))\n",
    "        F_b = self.F_b(h_embedded.view(self.batch_size,-1))\n",
    "        F_a = F.relu(F_a).view(self.batch_size,-1,self.embedding_dim)\n",
    "        F_b = F.relu(F_b).view(self.batch_size,-1,self.embedding_dim)\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        NEW MULTILAYER PERCEPTRON\n",
    "        '''\n",
    "        F_a = self.mlp_f(p_projected.view(-1, self.hidden_size)).view(self.batch_size,-1,self.hidden_size)\n",
    "        F_b = self.mlp_f(h_projected.view(-1, self.hidden_size)).view(self.batch_size,-1,self.hidden_size)\n",
    "        \n",
    "        \n",
    "        #E dim: batch_size x max len of hypothesis x max len of premise\n",
    "        #transpose function swaps second and third axis so that F_b is batch size x hidden dim x len premise\n",
    "        E = torch.matmul(F_a,torch.transpose(F_b,1,2))  \n",
    "        \n",
    "        '''\n",
    "        Attention! \n",
    "        Given E, we reweight using the softmax and store in W_beta, W_alpha\n",
    "        W_beta dim: batch_size x len(hypothesis) x embedding dimensions\n",
    "        W_alpha dim: batch_size x len(premise) x embedding dimensions\n",
    "        '''\n",
    "        W_beta = Variable(torch.Tensor(self.batch_size,self.p_len,self.hidden_size))\n",
    "        W_alpha = Variable(torch.Tensor(self.batch_size,self.h_len,self.hidden_size))\n",
    "        '''\n",
    "        TO DO: vectorize this with softmax on dimension (should be in next release of pytorch)\n",
    "        '''\n",
    "        for i in range(self.batch_size):\n",
    "            for j in range(F_b.size()[1]):\n",
    "                W_beta[i,j] = torch.mm(F.softmax(E[i,j]).view(1,-1),h_projected[i]).data\n",
    "            for k in range(F_a.size()[1]):\n",
    "                W_alpha[i,j] = torch.mm(F.softmax(E[i,:,j]).view(1,-1),p_projected[i]).data\n",
    "        \n",
    "        '''\n",
    "        Compare\n",
    "        Open items:\n",
    "        1) Check that we're concatenating along the right dimensions.  Based on AllenNLP and libowen, \n",
    "            concatenated input should be batch size x len(hypothesis/premise) x (2 * embedding dim)\n",
    "        \n",
    "        Output:\n",
    "        v1 dim: batch_size x len(hypothesis) x compare_dim\n",
    "        v2 dim: batch_size x len(premise) x compare_dim\n",
    "        '''\n",
    "        #dim: batch size x len(hypotheis/premise) x (2* embedding dim)\n",
    "        cat_p_beta = torch.cat((p_projected,W_beta),2)\n",
    "        cat_h_alpha = torch.cat((h_projected,W_alpha),2)\n",
    "        '''\n",
    "        OLD SINGLE LAYER\n",
    "        G_a = self.G_a(cat_p_beta.view(-1,2*self.embedding_dim)).view(self.batch_size,-1,self.compare_dim)\n",
    "        G_b = self.G_b(cat_h_alpha.view(-1,2*self.embedding_dim)).view(self.batch_size,-1,self.compare_dim)\n",
    "        v_a = F.relu(G_a).view(self.batch_size,-1,self.compare_dim)\n",
    "        v_b = F.relu(G_b).view(self.batch_size,-1,self.compare_dim)\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        NEW MULTILAYER PERCEPTRON\n",
    "        '''\n",
    "        v_a = self.mlp_g(cat_p_beta.view(-1, 2*self.hidden_size)).view(self.batch_size,-1,self.hidden_size)\n",
    "        v_b = self.mlp_g(cat_h_alpha.view(-1, 2*self.hidden_size)).view(self.batch_size,-1,self.hidden_size)\n",
    "        '''\n",
    "        Aggregate\n",
    "        Given:\n",
    "        v_a = output of relu activation on the concatenation of a (premise) and beta\n",
    "        v_b = output of relu activation on the concatenation of b (hypothesis) and alpha\n",
    "        '''\n",
    "        v1 = torch.sum(v_a, dim=1)\n",
    "        v2 = torch.sum(v_b, dim=1)\n",
    "        #H = F.relu(torch.cat((v1,v2),1))\n",
    "        \n",
    "        H = self.mlp_h(torch.cat((v1,v2),1))\n",
    "        H = self.final_linear(H)\n",
    "        out = F.softmax(H)\n",
    "        \n",
    "        #print(\"runtime for single batch: %s seconds\" % (time.time() - start_time))\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.embed.weight.data.copy_(torch.from_numpy(self.glove))\n",
    "        #does not train embedded weights\n",
    "        self.embed.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TESTING FOR SINGLE BATCH'''\n",
    "'''This should go in the training loop once our batch iterator is working:'''\n",
    "da = DecomposableAttention(embeddings,batch_size,200,\\\n",
    "                           h_len,p_len,num_classes,dropout=dropout_rate)\n",
    "optimizer.zero_grad()\n",
    "out = da(h_test_batch,p_test_batch,l_test_batch)\n",
    "#loss = criterion(output,l_test_batch.view(-1))\n",
    "#loss.backward()\n",
    "#optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def  batch_iter(dataset_size, hypothesis, premise, label_enc, batch_size, hLen, pLen):  \n",
    "    start        = -1 * batch_size\n",
    "    order        = list(range(dataset_size))\n",
    "    random.shuffle(order)\n",
    "\n",
    "    while True:\n",
    "        start     += batch_size\n",
    "        if start > dataset_size - batch_size:\n",
    "            # Start another epoch.\n",
    "            start = 0\n",
    "            random.shuffle(order)\n",
    "\n",
    "        hBatch = torch.LongTensor(batch_size, hLen)\n",
    "        pBatch = torch.LongTensor(batch_size, pLen)\n",
    "        lBatch = torch.LongTensor(batch_size, 1)\n",
    "\n",
    "        idx_list = order[start:start + batch_size]\n",
    "        i = 0\n",
    "        for idx in idx_list:\n",
    "            hBatch[i] = torch.from_numpy(hypothesis[idx])\n",
    "            pBatch[i] = torch.from_numpy(premise[idx])\n",
    "            lBatch[i] = label_enc[idx]\n",
    "            i += 1\n",
    "            \n",
    "        hBatch = hBatch.long()\n",
    "        pBatch = pBatch.long()\n",
    "        lBatch = Variable(lBatch)\n",
    "\n",
    "        yield [hBatch, pBatch, lBatch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_loop(dataset_size, batch_size, num_epochs, model, data_iter, optimizer, criterion):\n",
    "    step = 0\n",
    "    epoch = 0\n",
    "    losses = []\n",
    "    total_batches = int(dataset_size / batch_size)\n",
    "    start_time = time.time()\n",
    "    while epoch <= num_epochs:\n",
    "        hypothesis, premise, label = next(data_iter) \n",
    "        #start_time = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(hypothesis, premise, label)\n",
    "        loss = criterion(output, label.view(-1))\n",
    "        \n",
    "        losses.append(loss.data[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % total_batches == 0:\n",
    "            epoch += 1\n",
    "            if epoch % 25 == 0:\n",
    "                print( \"Epoch:\", (epoch), \"Avg Loss:\", np.mean(losses)/(total_batches*epoch), \\\n",
    "                      \"Elapsed Time: \", (start_time - time.time()))\n",
    "                start_time = time.time()\n",
    "        step += 1\n",
    "        #print(\"runtime for single batch: %s seconds\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "dropout_rate = .2\n",
    "batch_size = 4\n",
    "hidden_size = 100\n",
    "h_len = 10\n",
    "p_len = 15\n",
    "num_epochs  = 10\n",
    "learning_rate = .05\n",
    "da = DecomposableAttention(embeddings,batch_size,hidden_size,\\\n",
    "                           h_len,p_len,num_classes,dropout=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters out embedding layer which is not tuned\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, da.parameters()), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(hypothesis)\n",
    "data_iter = batch_iter(dataset_size, h_idx, p_idx, label_enc, batch_size, h_len, p_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime for single batch: 0.03697085380554199 seconds\n",
      "runtime for single batch: 0.036566972732543945 seconds\n",
      "runtime for single batch: 0.03309011459350586 seconds\n",
      "runtime for single batch: 0.03649711608886719 seconds\n",
      "runtime for single batch: 0.03617095947265625 seconds\n",
      "runtime for single batch: 0.03495907783508301 seconds\n",
      "runtime for single batch: 0.03164505958557129 seconds\n",
      "runtime for single batch: 0.03224968910217285 seconds\n",
      "runtime for single batch: 0.0315098762512207 seconds\n",
      "runtime for single batch: 0.028032779693603516 seconds\n",
      "runtime for single batch: 0.029220104217529297 seconds\n",
      "runtime for single batch: 0.03051590919494629 seconds\n",
      "runtime for single batch: 0.030647993087768555 seconds\n",
      "runtime for single batch: 0.02989983558654785 seconds\n",
      "runtime for single batch: 0.034136056900024414 seconds\n",
      "runtime for single batch: 0.029687166213989258 seconds\n",
      "runtime for single batch: 0.029983997344970703 seconds\n",
      "runtime for single batch: 0.030369043350219727 seconds\n",
      "runtime for single batch: 0.030669212341308594 seconds\n",
      "runtime for single batch: 0.03204178810119629 seconds\n",
      "runtime for single batch: 0.032965898513793945 seconds\n",
      "runtime for single batch: 0.03240394592285156 seconds\n",
      "runtime for single batch: 0.027327775955200195 seconds\n",
      "runtime for single batch: 0.02606511116027832 seconds\n",
      "runtime for single batch: 0.029484033584594727 seconds\n",
      "runtime for single batch: 0.03034496307373047 seconds\n",
      "runtime for single batch: 0.027573585510253906 seconds\n",
      "runtime for single batch: 0.03022909164428711 seconds\n",
      "runtime for single batch: 0.03303813934326172 seconds\n",
      "runtime for single batch: 0.039225101470947266 seconds\n",
      "runtime for single batch: 0.02930617332458496 seconds\n",
      "runtime for single batch: 0.030892133712768555 seconds\n",
      "runtime for single batch: 0.030339956283569336 seconds\n",
      "runtime for single batch: 0.030978918075561523 seconds\n",
      "runtime for single batch: 0.0353388786315918 seconds\n",
      "runtime for single batch: 0.02886176109313965 seconds\n",
      "runtime for single batch: 0.030253887176513672 seconds\n",
      "runtime for single batch: 0.027798175811767578 seconds\n",
      "runtime for single batch: 0.0300290584564209 seconds\n",
      "runtime for single batch: 0.035284996032714844 seconds\n",
      "runtime for single batch: 0.03139996528625488 seconds\n",
      "runtime for single batch: 0.03240180015563965 seconds\n",
      "runtime for single batch: 0.033686161041259766 seconds\n",
      "runtime for single batch: 0.03160715103149414 seconds\n",
      "runtime for single batch: 0.03067493438720703 seconds\n",
      "runtime for single batch: 0.03167533874511719 seconds\n",
      "runtime for single batch: 0.030736684799194336 seconds\n",
      "runtime for single batch: 0.027999162673950195 seconds\n",
      "runtime for single batch: 0.02634716033935547 seconds\n",
      "runtime for single batch: 0.03283286094665527 seconds\n",
      "runtime for single batch: 0.03007197380065918 seconds\n",
      "runtime for single batch: 0.03354692459106445 seconds\n",
      "runtime for single batch: 0.032334089279174805 seconds\n",
      "runtime for single batch: 0.03151226043701172 seconds\n",
      "runtime for single batch: 0.03144073486328125 seconds\n",
      "runtime for single batch: 0.034545183181762695 seconds\n",
      "runtime for single batch: 0.03466606140136719 seconds\n",
      "runtime for single batch: 0.032147884368896484 seconds\n",
      "runtime for single batch: 0.029000043869018555 seconds\n",
      "runtime for single batch: 0.029526948928833008 seconds\n",
      "runtime for single batch: 0.028856992721557617 seconds\n",
      "runtime for single batch: 0.03047323226928711 seconds\n",
      "runtime for single batch: 0.03856205940246582 seconds\n",
      "runtime for single batch: 0.03484511375427246 seconds\n",
      "runtime for single batch: 0.033188819885253906 seconds\n",
      "runtime for single batch: 0.029871225357055664 seconds\n",
      "runtime for single batch: 0.02412867546081543 seconds\n",
      "runtime for single batch: 0.02855396270751953 seconds\n",
      "runtime for single batch: 0.028132915496826172 seconds\n",
      "runtime for single batch: 0.027143001556396484 seconds\n",
      "runtime for single batch: 0.03208804130554199 seconds\n",
      "runtime for single batch: 0.03877401351928711 seconds\n",
      "runtime for single batch: 0.03787684440612793 seconds\n",
      "runtime for single batch: 0.03868889808654785 seconds\n",
      "runtime for single batch: 0.03520679473876953 seconds\n",
      "runtime for single batch: 0.03728818893432617 seconds\n",
      "runtime for single batch: 0.03551483154296875 seconds\n",
      "runtime for single batch: 0.034851789474487305 seconds\n",
      "runtime for single batch: 0.034802913665771484 seconds\n",
      "runtime for single batch: 0.031058073043823242 seconds\n",
      "runtime for single batch: 0.024431943893432617 seconds\n",
      "runtime for single batch: 0.033083200454711914 seconds\n",
      "runtime for single batch: 0.03319191932678223 seconds\n",
      "runtime for single batch: 0.03297305107116699 seconds\n",
      "runtime for single batch: 0.0351409912109375 seconds\n",
      "runtime for single batch: 0.030955791473388672 seconds\n",
      "runtime for single batch: 0.028522014617919922 seconds\n",
      "runtime for single batch: 0.03016519546508789 seconds\n",
      "runtime for single batch: 0.029642820358276367 seconds\n",
      "runtime for single batch: 0.026942014694213867 seconds\n",
      "runtime for single batch: 0.03236818313598633 seconds\n",
      "runtime for single batch: 0.04062676429748535 seconds\n",
      "runtime for single batch: 0.03617715835571289 seconds\n",
      "runtime for single batch: 0.027730941772460938 seconds\n",
      "runtime for single batch: 0.028888940811157227 seconds\n",
      "runtime for single batch: 0.026495933532714844 seconds\n",
      "runtime for single batch: 0.032855987548828125 seconds\n",
      "runtime for single batch: 0.032119035720825195 seconds\n",
      "runtime for single batch: 0.032850027084350586 seconds\n",
      "runtime for single batch: 0.03509211540222168 seconds\n",
      "runtime for single batch: 0.027318954467773438 seconds\n",
      "runtime for single batch: 0.028198957443237305 seconds\n",
      "runtime for single batch: 0.03127694129943848 seconds\n",
      "runtime for single batch: 0.03537607192993164 seconds\n",
      "runtime for single batch: 0.037016868591308594 seconds\n",
      "runtime for single batch: 0.03241109848022461 seconds\n",
      "runtime for single batch: 0.03190493583679199 seconds\n",
      "runtime for single batch: 0.03167319297790527 seconds\n",
      "runtime for single batch: 0.024235963821411133 seconds\n",
      "runtime for single batch: 0.03128480911254883 seconds\n",
      "runtime for single batch: 0.02626776695251465 seconds\n",
      "runtime for single batch: 0.03230619430541992 seconds\n",
      "runtime for single batch: 0.03653979301452637 seconds\n",
      "runtime for single batch: 0.03652215003967285 seconds\n",
      "runtime for single batch: 0.033556222915649414 seconds\n",
      "runtime for single batch: 0.03106975555419922 seconds\n",
      "runtime for single batch: 0.03134584426879883 seconds\n",
      "runtime for single batch: 0.034287214279174805 seconds\n",
      "runtime for single batch: 0.037878990173339844 seconds\n",
      "runtime for single batch: 0.028641700744628906 seconds\n",
      "runtime for single batch: 0.031409263610839844 seconds\n",
      "runtime for single batch: 0.02733898162841797 seconds\n",
      "runtime for single batch: 0.031098127365112305 seconds\n",
      "runtime for single batch: 0.03313899040222168 seconds\n",
      "runtime for single batch: 0.0332181453704834 seconds\n",
      "runtime for single batch: 0.03446030616760254 seconds\n",
      "runtime for single batch: 0.033193111419677734 seconds\n",
      "runtime for single batch: 0.0318448543548584 seconds\n",
      "runtime for single batch: 0.02875208854675293 seconds\n",
      "runtime for single batch: 0.03164100646972656 seconds\n",
      "runtime for single batch: 0.033386945724487305 seconds\n",
      "runtime for single batch: 0.03432512283325195 seconds\n",
      "runtime for single batch: 0.03491473197937012 seconds\n",
      "runtime for single batch: 0.03202700614929199 seconds\n",
      "runtime for single batch: 0.03055095672607422 seconds\n",
      "runtime for single batch: 0.026488065719604492 seconds\n",
      "runtime for single batch: 0.030192852020263672 seconds\n",
      "runtime for single batch: 0.03282928466796875 seconds\n",
      "runtime for single batch: 0.03639411926269531 seconds\n",
      "runtime for single batch: 0.03390192985534668 seconds\n",
      "runtime for single batch: 0.030779123306274414 seconds\n",
      "runtime for single batch: 0.030726909637451172 seconds\n",
      "runtime for single batch: 0.03114914894104004 seconds\n",
      "runtime for single batch: 0.03138017654418945 seconds\n",
      "runtime for single batch: 0.03104114532470703 seconds\n",
      "runtime for single batch: 0.03314995765686035 seconds\n",
      "runtime for single batch: 0.032843828201293945 seconds\n",
      "runtime for single batch: 0.03092503547668457 seconds\n",
      "runtime for single batch: 0.030277013778686523 seconds\n",
      "runtime for single batch: 0.029206037521362305 seconds\n",
      "runtime for single batch: 0.03088688850402832 seconds\n",
      "runtime for single batch: 0.0292818546295166 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime for single batch: 0.03280496597290039 seconds\n",
      "runtime for single batch: 0.03227496147155762 seconds\n",
      "runtime for single batch: 0.03415393829345703 seconds\n",
      "runtime for single batch: 0.03125786781311035 seconds\n",
      "runtime for single batch: 0.03028583526611328 seconds\n",
      "runtime for single batch: 0.02788710594177246 seconds\n",
      "runtime for single batch: 0.029569149017333984 seconds\n",
      "runtime for single batch: 0.03298020362854004 seconds\n",
      "runtime for single batch: 0.032543182373046875 seconds\n",
      "runtime for single batch: 0.03151822090148926 seconds\n",
      "runtime for single batch: 0.03180122375488281 seconds\n",
      "runtime for single batch: 0.03477978706359863 seconds\n",
      "runtime for single batch: 0.03230595588684082 seconds\n",
      "runtime for single batch: 0.030761003494262695 seconds\n",
      "runtime for single batch: 0.034507036209106445 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-270-b4c176b9488c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-251-c8c8ea6dec8e>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(dataset_size, batch_size, num_epochs, model, data_iter, optimizer, criterion)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpremise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-268-ad44384128ea>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hypothesis, premise, label)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mW_beta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_projected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0mW_alpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_projected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         '''\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mview\u001b[0;34m(self, *sizes)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mView\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_loop(dataset_size, batch_size, num_epochs, da, data_iter, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approximate minutes for a single epoch:  80.97686044971148\n"
     ]
    }
   ],
   "source": [
    "print('approximate minutes for a single epoch: ',(dataset_size/4*0.03537607192993164/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
