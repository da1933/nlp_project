{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pickle as pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_chars = ['\\\\','.',',','/','\\'s']\n",
    "start = ['<null>']\n",
    "\n",
    "label_dict = {'neutral':0,'contradiction':-1,'entailment':1}\n",
    "\n",
    "def load_data(path): #load SNLI words\n",
    "    '''\n",
    "    Constructs 4 dictionaries with the same key values across the dictionaries\n",
    "    '''\n",
    "    #data = []\n",
    "    excluded = 0\n",
    "    hypothesis = {}\n",
    "    premise = {}\n",
    "    label = {}\n",
    "    label_enc = {}\n",
    "    with open(path, 'r') as f:\n",
    "        #need this so indexing is continuous when setences are skipped over\n",
    "        idx = 0\n",
    "        for i,line in enumerate(f):\n",
    "            obj = json.loads(line)\n",
    "            #skip these rows per readme\n",
    "            if obj[\"gold_label\"] == '-':\n",
    "                excluded += 1\n",
    "            else:\n",
    "                label[idx] = obj[\"gold_label\"]\n",
    "                label_enc[idx] = label_dict[obj[\"gold_label\"]]\n",
    "                premise[idx] = obj[\"sentence1\"]\n",
    "                hypothesis[idx] = obj[\"sentence2\"]\n",
    "                idx += 1\n",
    "    print('%s excluded' %excluded)\n",
    "    return hypothesis, premise, label, label_enc\n",
    "\n",
    "def load_embeddings(path,number_of_words,emb_dim): #load pre-trained GloVe embeddings\n",
    "    words_to_load = number_of_words\n",
    "\n",
    "    with open(path) as f:\n",
    "        loaded_embeddings = np.zeros((words_to_load, emb_dim))\n",
    "        words = {}\n",
    "        idx2words = {}\n",
    "        ordered_words = []\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= words_to_load: \n",
    "                break\n",
    "            s = line.split()\n",
    "            loaded_embeddings[i, :] = np.asarray(s[1:])\n",
    "            words[s[0]] = i\n",
    "            idx2words[i] = s[0]\n",
    "            ordered_words.append(s[0])\n",
    "\n",
    "    return loaded_embeddings, words, idx2words, ordered_words\n",
    "\n",
    "def clean_words(text_list): # Removes characters and makes all words lowercase\n",
    "    for i,word in enumerate(text_list):\n",
    "        for ch in unwanted_chars:\n",
    "            if ch in text_list[i]:\n",
    "                text_list[i] = text_list[i].replace(ch,'')\n",
    "            text_list[i] = text_list[i].lower()\n",
    "            \n",
    "def add_tokens(idx_mapping, embeddings, emb_dim):\n",
    "    '''\n",
    "    This function increases the index of the word to index mapping for GloVe so that\n",
    "    0: padding index\n",
    "    1: unk\n",
    "    2: BoS\n",
    "    '''\n",
    "    words_cnt = Counter(idx_mapping)\n",
    "    increment = Counter(dict.fromkeys(words, 3))\n",
    "    words_cnt = words_cnt + increment\n",
    "    words_cnt['<PAD_IDX>'] = 0\n",
    "    words_cnt['<UNK>'] = 1\n",
    "    words_cnt['<BoS>'] = 2\n",
    "    \n",
    "    #insert embeddings for tokens\n",
    "    '''\n",
    "    TO DO: FIX INITILIZATION\n",
    "    '''\n",
    "    #<BoS>\n",
    "    embed = np.insert(embeddings,[0],np.random.rand(300),axis=0)\n",
    "    #<UNK>\n",
    "    embed = np.insert(embeddings,[0],np.random.rand(300),axis=0)\n",
    "    #<PAD_IDX>\n",
    "    embed = np.insert(embeddings,[0],np.zeros(300),axis=0)\n",
    "    \n",
    "    return words_cnt, embed\n",
    "\n",
    "def clean_words(text_list): # Removes characters and makes all words lowercase\n",
    "    for i,word in enumerate(text_list):\n",
    "        for ch in unwanted_chars:\n",
    "            if ch in text_list[i]:\n",
    "                text_list[i] = text_list[i].replace(ch,'')\n",
    "            text_list[i] = text_list[i].lower()\n",
    "\n",
    "def tokenize(text_dict, idx_mapping):\n",
    "    '''\n",
    "    text_dict: dictionary with index as key, sentence as value\n",
    "    returns dictionary with the index as key, setenece mapped to index as value\n",
    "    '''\n",
    "    tokenized_data = {}\n",
    "    for i in range(len(text_dict.keys())):\n",
    "        text_list = text_dict[i].split()\n",
    "        clean_words(text_list)\n",
    "        text_idx = []\n",
    "        for word in text_list:\n",
    "            try:\n",
    "                text_idx.append(idx_mapping[word])\n",
    "            except KeyError:\n",
    "                #UNK token\n",
    "                text_idx.append(1)\n",
    "                continue\n",
    "        #insert BoS token\n",
    "        text_idx.insert(0,2)\n",
    "        tokenized_data[i] = np.array(text_idx)\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_h = {0:hypothesis[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 50000\n",
    "emb_dim = 300\n",
    "glove_path = '/Users/Lisa/Documents/Grad School/DS-GA 1101/data/glove.6B/glove.6B.300d.txt'\n",
    "text_path = '/Users/Lisa/Documents/Grad School/DS-GA 1101/data/snli_1.0/snli_1.0_train.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785 excluded\n"
     ]
    }
   ],
   "source": [
    "hypothesis, premise, label, label_enc = load_data(text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings, words, idx2words, ordered_words = load_embeddings(glove_path, vocab_size, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modifies embeddings, words, idx2words in place to add tokens\n",
    "words, embeddings = add_tokens(words, embeddings, emb_dim)\n",
    "idx2words = {v:k for k,v in words.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_idx = tokenize(hypothesis, words)\n",
    "p_idx = tokenize(premise, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = '/Users/Lisa/Documents/Grad School/DS-GA 1101/data/pickles/'\n",
    "with open(fp+'h_idx.pt', 'wb') as f:\n",
    "    pickle.dump(h_idx, f)\n",
    "with open(fp+'p_idx.pt', 'wb') as f:\n",
    "    pickle.dump(p_idx, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample indices\n",
    "idx_list = np.array((0,1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_test_batch = torch.LongTensor(4, h_max_len)\n",
    "p_test_batch = torch.LongTensor(4, p_max_len)\n",
    "p_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad batch\n",
    "h_max_len = max([len(h_idx[x]) for x in idx_list])\n",
    "p_max_len = max([len(p_idx[x]) for x in idx_list])\n",
    "h_test_batch = torch.Tensor(4, h_max_len)\n",
    "p_test_batch = torch.Tensor(4, p_max_len)\n",
    "p_max_len\n",
    "for i in range(4):\n",
    "    h_test_batch[i] = torch.from_numpy(\\\n",
    "                    np.concatenate((h_idx[idx_list[i]],np.zeros(max(h_max_len-len(h_idx[idx_list[i]]),0))))\\\n",
    "                                    )\n",
    "    p_test_batch[i] = torch.from_numpy(\\\n",
    "                    np.concatenate((p_idx[idx_list[i]],np.zeros(max(p_max_len-len(p_idx[idx_list[i]]),0))))\\\n",
    "                                    )\n",
    "h_test_batch=h_test_batch.long()\n",
    "p_test_batch=p_test_batch.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "     2     10    902     17    791     29   2870     13     10    994\n",
       "     2     10    902     17     25     10  19304   7490     32      0\n",
       "     2     10    902     17  13080     16     10   2870      0      0\n",
       "     2     42     35   8784     25     47   1111      0      0      0\n",
       "[torch.LongTensor of size 4x10]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD\n",
    "class DecomposableAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size, glove_emb, hidden_dim, num_labels):\n",
    "        super(DecomposableAttention, self).__init__()\n",
    "        self.glove = glove_emb\n",
    "        self.num_embeddings = glove_emb.shape[0]\n",
    "        self.embedding_dim = glove_emb.shape[1]\n",
    "        \n",
    "        \n",
    "        self.embed = nn.Embedding(self.num_embeddings, self.embedding_dim)\n",
    "        \n",
    "        self.a_linear = nn.Linear(self.embedding_dim,self.embedding_dim)\n",
    "        self.b_linear = nn.Linear(self.embedding_dim,self.embedding_dim)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, hypothesis, premise):\n",
    "        \n",
    "        '''\n",
    "        Embedding layer\n",
    "        max length = max length of of hypothesis/premise (respectively) in batch\n",
    "        Input dim: batch size x max length\n",
    "        Output dim: batch size x max length x embedding dimensions\n",
    "        '''\n",
    "        h_embedded = self.embed(Variable(hypothesis))\n",
    "        p_embedded = self.embed(Variable(premise))\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Relu layer (F from paper)\n",
    "        max length = max length of of hypothesis/premise (respectively) in batch\n",
    "        Input dim: batch size x (max length*embedding dimensions)\n",
    "        Output dim: batch size x (max length*embedding dimensions)\n",
    "        \n",
    "        CHECK THAT THE RESHAPING IS CORRECT\n",
    "        '''\n",
    "        #input is reshaped to batch_size x (max length*embedding dimensions)\n",
    "        #this is equivalent to having each 300 length embedding appended horizontally for each word\n",
    "        F_a = F.relu(h_embedded.view(batch_size,-1))\n",
    "        F_b = F.relu(p_embedded.view(batch_size,-1))\n",
    "        #E dim: (max length of hypothesis*embedding dimensions) x (max length of premise*embedding dimensions)\n",
    "        E = torch.mm(torch.transpose(F_a,0,1),F_b)\n",
    "        \n",
    "        '''\n",
    "        TO DO: ATTENTION STEP\n",
    "        we can use probs use torch.nn.Softmax\n",
    "        '''\n",
    "        \n",
    "        return F_a, F_b, E\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.embed.weight.data.copy_(torch.from_numpy(self.glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = DecomposableAttention(4,embeddings,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_a, F_b, E = da.forward(h_test_batch,p_test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0000  0.0000  0.1317  ...   0.1720  0.0000  0.0000\n",
       " 0.0000  0.0000  0.1317  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.1317  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.1317  ...   0.0000  0.0000  0.0000\n",
       "[torch.FloatTensor of size 4x3000]"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  0.0000   0.0000   0.0000  ...    0.0000   0.0000   0.0000\n",
       "  0.0000   0.0000   0.0000  ...    0.0000   0.0000   0.0000\n",
       "  0.0000   0.0000   0.0694  ...    0.0000   0.3091   0.0808\n",
       "           ...               ⋱              ...            \n",
       "  0.0000   0.0000   0.0227  ...    0.0000   0.1346   0.0352\n",
       "  0.0000   0.0000   0.0000  ...    0.0000   0.0000   0.0000\n",
       "  0.0000   0.0000   0.0000  ...    0.0000   0.0000   0.0000\n",
       "[torch.FloatTensor of size 3000x3600]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.1329\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_test.view(4,-1)[3][300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.3292e-01\n",
       " 1.6985e-01\n",
       "-1.4360e-01\n",
       "-8.8722e-02\n",
       " 7.9510e-02\n",
       "-1.4212e-01\n",
       "-2.4209e-02\n",
       "-2.6291e-01\n",
       "-7.4814e-02\n",
       "-2.3600e+00\n",
       " 3.4830e-01\n",
       "-9.1722e-02\n",
       "-5.3906e-02\n",
       " 3.0418e-01\n",
       "-1.3286e-01\n",
       " 5.0341e-03\n",
       "-1.5056e-01\n",
       " 2.3562e-03\n",
       " 6.8321e-02\n",
       " 3.4246e-01\n",
       " 3.9891e-01\n",
       " 5.8813e-01\n",
       " 6.0618e-02\n",
       "-1.9871e-01\n",
       "-4.0465e-01\n",
       "-1.0706e-01\n",
       "-5.9312e-03\n",
       "-6.4842e-01\n",
       " 1.9080e-01\n",
       "-1.7630e-01\n",
       " 9.2407e-02\n",
       " 3.8685e-01\n",
       "-3.1085e-01\n",
       "-3.2574e-01\n",
       "-1.6823e+00\n",
       " 2.5336e-01\n",
       "-2.4647e-01\n",
       "-1.0874e-01\n",
       " 7.6402e-03\n",
       " 3.3880e-01\n",
       "-5.9736e-02\n",
       "-8.5940e-01\n",
       "-8.0964e-02\n",
       "-2.2981e-01\n",
       " 1.7709e-01\n",
       " 8.2094e-02\n",
       " 7.4416e-01\n",
       " 3.6873e-01\n",
       " 1.3740e-01\n",
       " 2.9408e-01\n",
       " 1.0647e-01\n",
       "-1.3246e-01\n",
       " 1.2134e-01\n",
       "-1.4273e-01\n",
       "-5.3270e-01\n",
       " 6.4936e-01\n",
       " 4.9657e-01\n",
       " 3.0029e-01\n",
       " 6.7226e-01\n",
       " 1.8005e-01\n",
       " 8.8050e-01\n",
       " 3.8144e-02\n",
       "-8.7140e-02\n",
       " 7.6400e-01\n",
       "-1.2107e-01\n",
       "-4.2809e-01\n",
       "-1.2588e-01\n",
       " 8.8377e-04\n",
       " 1.0596e-01\n",
       "-3.0802e-01\n",
       " 2.2887e-01\n",
       "-2.5468e-01\n",
       "-3.6484e-01\n",
       " 7.4524e-01\n",
       "-1.5217e-01\n",
       "-5.5619e-02\n",
       " 1.2049e-01\n",
       " 3.9876e-01\n",
       "-2.1991e-01\n",
       "-1.8444e-01\n",
       "-9.0398e-02\n",
       " 1.4077e-01\n",
       " 1.2865e+00\n",
       "-4.0910e-01\n",
       " 2.7999e-01\n",
       " 4.2089e-01\n",
       "-7.0627e-01\n",
       " 7.9004e-01\n",
       " 1.3804e-01\n",
       " 3.0273e-01\n",
       "-1.8534e-01\n",
       " 1.8121e-01\n",
       "-7.1732e-01\n",
       "-5.4259e-01\n",
       "-2.2513e-03\n",
       " 3.0463e-01\n",
       "-4.9588e-01\n",
       "-1.7462e-01\n",
       " 2.1335e-02\n",
       "-2.1341e-01\n",
       "-8.2391e-02\n",
       "-3.7676e-01\n",
       "-2.8001e-01\n",
       "-2.4238e-01\n",
       "-3.5249e-01\n",
       "-2.4116e-01\n",
       " 2.9776e-01\n",
       " 3.7027e-01\n",
       "-1.7822e-01\n",
       " 4.7537e-01\n",
       "-7.3484e-02\n",
       "-2.9747e-01\n",
       "-3.6304e-02\n",
       "-8.4941e-01\n",
       " 4.5171e-02\n",
       " 2.8779e-01\n",
       "-1.7543e-01\n",
       "-2.7925e-01\n",
       "-9.9789e-02\n",
       "-1.3493e-01\n",
       "-7.8184e-02\n",
       "-3.5548e-01\n",
       " 2.1692e-01\n",
       " 2.5895e-01\n",
       " 2.6050e-01\n",
       "-4.3193e-01\n",
       " 1.2076e-01\n",
       " 2.8405e-01\n",
       " 1.5691e-01\n",
       " 2.1351e-01\n",
       " 5.7355e-01\n",
       "-4.7598e-01\n",
       " 4.5758e-02\n",
       " 6.5907e-02\n",
       "-2.4157e-01\n",
       " 1.5724e-01\n",
       "-3.9697e-01\n",
       "-8.7238e-02\n",
       " 1.1132e-02\n",
       " 4.6365e-01\n",
       "-4.3082e-02\n",
       " 5.6318e-01\n",
       " 5.2448e-01\n",
       " 3.8723e-01\n",
       "-4.4893e-01\n",
       "-3.6617e-03\n",
       "-1.4007e-01\n",
       " 2.9963e-02\n",
       "-1.4168e-01\n",
       " 5.1547e-02\n",
       "-7.6266e-01\n",
       "-8.0719e-02\n",
       "-1.0827e-01\n",
       " 2.0345e-02\n",
       "-1.4594e-01\n",
       " 1.3781e-01\n",
       " 3.5217e-01\n",
       "-1.9425e-01\n",
       " 4.7376e-01\n",
       "-2.7950e-01\n",
       "-8.3159e-02\n",
       "-6.1386e-01\n",
       "-3.4310e-01\n",
       "-9.9814e-02\n",
       "-2.4054e-02\n",
       " 2.0529e-01\n",
       "-2.2244e-02\n",
       " 5.9102e-01\n",
       " 1.7002e-01\n",
       " 5.2526e-02\n",
       "-1.9144e-01\n",
       " 1.2114e-01\n",
       "-5.0691e-01\n",
       "-5.1987e-01\n",
       " 5.4760e-02\n",
       " 1.5022e-01\n",
       " 9.2612e-02\n",
       " 3.4548e-01\n",
       " 3.5603e-01\n",
       " 2.3423e-01\n",
       " 1.3452e-01\n",
       " 1.5486e-02\n",
       " 1.7266e-01\n",
       "-1.8454e-01\n",
       "-9.8682e-02\n",
       "-2.1803e-01\n",
       "-1.5786e-01\n",
       " 7.0495e-01\n",
       " 3.6798e-01\n",
       " 2.6764e-01\n",
       "-1.4352e-01\n",
       "-5.4373e-02\n",
       " 4.3326e-01\n",
       "-1.6332e-01\n",
       " 2.1658e-02\n",
       "-5.3408e-01\n",
       "-2.5548e-02\n",
       " 4.1534e-01\n",
       "-1.6234e-01\n",
       "-4.0243e-01\n",
       " 2.0005e+00\n",
       "-1.3084e-01\n",
       " 1.1824e-01\n",
       " 1.8055e-01\n",
       " 3.1811e-01\n",
       " 1.5508e-01\n",
       " 3.6686e-02\n",
       " 3.0747e-01\n",
       " 1.9520e-01\n",
       "-4.4309e-02\n",
       "-6.5875e-01\n",
       " 1.8604e-01\n",
       "-1.6245e-01\n",
       " 4.0257e-02\n",
       "-5.3955e-01\n",
       "-1.2123e-02\n",
       "-3.0579e-03\n",
       " 1.7945e-02\n",
       " 1.4503e-01\n",
       "-3.5640e-01\n",
       " 4.3888e-01\n",
       "-1.1453e-01\n",
       "-1.5161e-01\n",
       " 2.4664e-01\n",
       " 4.3432e-01\n",
       " 3.1283e-01\n",
       " 4.2919e-01\n",
       "-1.2493e-01\n",
       "-1.1767e-01\n",
       "-2.2056e-04\n",
       "-3.5881e-01\n",
       "-6.7778e-02\n",
       " 2.1444e-01\n",
       "-7.9171e-01\n",
       "-1.1005e-01\n",
       " 3.0940e-01\n",
       "-3.0179e-03\n",
       " 1.3354e-01\n",
       "-2.0436e-01\n",
       "-1.6333e-01\n",
       "-4.8577e-02\n",
       "-5.1513e-02\n",
       " 3.1318e-02\n",
       " 3.6954e-01\n",
       "-4.7448e-02\n",
       "-7.6416e-02\n",
       "-7.8986e-05\n",
       "-7.2528e-02\n",
       "-8.4875e-02\n",
       "-1.4013e-01\n",
       " 2.0147e-01\n",
       "-2.7516e-01\n",
       "-4.8958e-02\n",
       " 3.1184e-01\n",
       " 7.1849e-01\n",
       " 3.0594e-01\n",
       " 4.7019e-01\n",
       "-2.8368e-01\n",
       " 1.0073e-01\n",
       "-4.1866e-01\n",
       " 1.7655e-01\n",
       "-1.2393e-01\n",
       "-4.7247e-02\n",
       "-8.9221e-02\n",
       " 6.8069e-02\n",
       " 1.4806e-02\n",
       "-2.8357e-01\n",
       "-2.5358e-01\n",
       " 1.3204e-01\n",
       " 6.9809e-01\n",
       "-8.4020e-02\n",
       "-4.2223e-01\n",
       " 5.5961e-01\n",
       " 3.9954e-02\n",
       " 5.8968e-02\n",
       "-1.9102e-01\n",
       "-2.2069e+00\n",
       " 8.1526e-02\n",
       " 2.5289e-01\n",
       "-2.2367e-01\n",
       "-3.0142e-01\n",
       "-2.8467e-01\n",
       "-8.7759e-02\n",
       "-3.9672e-01\n",
       "-2.4318e-01\n",
       " 1.4144e-01\n",
       "-1.2311e-01\n",
       " 6.3953e-03\n",
       "-3.4761e-01\n",
       "-4.6531e-01\n",
       "-1.0615e-03\n",
       "-3.9291e-01\n",
       "-1.7780e-01\n",
       "-1.2175e-01\n",
       " 2.4335e-01\n",
       "-7.7835e-01\n",
       " 3.9598e-01\n",
       "-2.3778e-01\n",
       " 1.4766e-01\n",
       " 6.2902e-01\n",
       "[torch.FloatTensor of size 300]"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_test[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_iter(source):\n",
    "    #tbd\n",
    "    return None\n",
    "    \n",
    "def data_iter(source, batch_size):\n",
    "    dataset_size = len(source)\n",
    "    start = -1 * batch_size\n",
    "    order = list(range(dataset_size))\n",
    "    random.shuffle(order)\n",
    "\n",
    "    while True:\n",
    "        start += batch_size\n",
    "        if start > dataset_size - batch_size:\n",
    "            # Start another epoch.\n",
    "            start = 0\n",
    "            random.shuffle(order)   \n",
    "        batch_indices = order[start:start + batch_size]\n",
    "        yield [source[index] for index in batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Note that the Decomposable attention paper selected batch_size=4\"\"\"\n",
    "data_iter = data_iter(train_data,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TBD\n",
    "class DecomposableAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, embedding_dim, hidden_dim, num_labels):\n",
    "        super(DecomposableAttention, self).__init__()\n",
    "        #self.dropout = nn.Dropout(p=0.5)\n",
    "            \n",
    "        self.a_linear = nn.Linear(embedding_dim,embedding_dim)\n",
    "        self.b_linear = nn.Linear(embedding_dim,embedding_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input through your layers in order\n",
    "        \n",
    "        a_relu = F.relu(self.a_linear)\n",
    "        b_relu = F.relu(self.b_linear)\n",
    "        \n",
    "        return \n",
    "\n",
    "    def init_weights(self):\n",
    "        '''tbd'''\n",
    "        initrange = 0.1\n",
    "        lin_layers = [self.linear_1, self.linear_2]\n",
    "             \n",
    "        for layer in lin_layers:\n",
    "            layer.weight.data.uniform_(-initrange, initrange)\n",
    "            if layer in lin_layers:\n",
    "                layer.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_bar = Variable(torch.Tensor(train_data[1432]['premise']))\n",
    "b_bar = Variable(torch.Tensor(train_data[1432]['hypothesis']))\n",
    "\n",
    "a_linear = nn.Linear(300,300)\n",
    "b_linear = nn.Linear(300,300)\n",
    "\n",
    "a_relu = F.relu(a_linear(a_bar))\n",
    "b_relu = F.relu(b_linear(b_bar))\n",
    "\n",
    "e_ij = torch.matmul(a_relu,torch.transpose(b_relu,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_weights(e,a_input,b_input):\n",
    "    ''' Part 3.1\n",
    "    Takes weight matrix e_ij, a_bar, and b_bar as inputs and returns \n",
    "    attention weight matrices alpha and beta.\n",
    "    The jth row in alpha aligns with the jth word in sentence b (the hypothesis).\n",
    "    The ith row in beta aligns with the ith word in sentence a (the premise)'''\n",
    "    len_a = b_input.data.numpy().shape[0]\n",
    "    len_b = a_input.data.numpy().shape[0]\n",
    "    \n",
    "    alphas = []\n",
    "    betas = []\n",
    "    for i in range(len_a):\n",
    "        alphas.append(torch.sum(a_input*torch.transpose(torch.exp(e_ij[:,i])/ \\\n",
    "                      torch.sum(torch.exp(e_ij),dim=0)[i].view(-1,1),0,1),dim=0))\n",
    "    for j in range(len_b):\n",
    "        betas.append(torch.sum(b_bar*torch.transpose(torch.exp(e_ij[i,:])/ \\\n",
    "                    torch.sum(torch.exp(e_ij),dim=1)[i].view(-1,1),0,1),dim=0))\n",
    "    \n",
    "    alpha = torch.stack(alphas)\n",
    "    beta = torch.stack(betas)\n",
    "    \n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " self.linear_1 = nn.Linear(embedding_dim, hidden_dim) \n",
    "        self.linear_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear_3 = nn.Linear(hidden_dim, num_labels)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input through your layers in order\n",
    "\n",
    "        out = F.relu(self.linear_1(out))\n",
    "        out = F.relu(self.linear_2(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
